{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb19ba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n",
      "📊 Ready for Alpha1 factor analysis with Alphalens\n",
      "🧮 Alpha1 Factor: (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries for Alpha1 Factor Analysis with Alphalens\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import alphalens\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import ccxt\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from scipy import stats\n",
    "\n",
    "# Configure plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (20, 16)\n",
    "plt.rcParams['font.size'] = 12\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(\"📊 Ready for Alpha1 factor analysis with Alphalens\")\n",
    "print(\"🧮 Alpha1 Factor: (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c1c0e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Alpha1 factor calculation functions defined!\n",
      "🔧 Functions available:\n",
      "  - fetch_crypto_data_from_exchanges(): Fetch crypto data directly from exchanges\n",
      "  - calculate_alpha1_factor(): Calculate Alpha1 factor with proper cross-sectional ranking\n",
      "  - prepare_crypto_prices_for_alphalens(): Prepare price data\n",
      "  - signed_power(): Apply signed power transformation\n",
      "  - ts_argmax(): Time-series ArgMax calculation\n"
     ]
    }
   ],
   "source": [
    "# Crypto Data Fetching Functions (Direct from Exchanges) + Alpha1 Factor Calculation\n",
    "\n",
    "def fetch_crypto_data_from_exchanges(cryptocurrencies=['BTC', 'ETH', 'SOL', 'ADA', 'DOT', 'LINK', 'MATIC', 'AVAX'], \n",
    "                                   exchanges=['okx'], \n",
    "                                   timeframe='1h', \n",
    "                                   days_back=365):\n",
    "    \"\"\"\n",
    "    Fetch cryptocurrency data directly from exchanges using ccxt.\n",
    "    \n",
    "    Args:\n",
    "        cryptocurrencies: List of cryptocurrencies to fetch\n",
    "        exchanges: List of exchanges to use\n",
    "        timeframe: Data timeframe ('1h', '4h', '1d')\n",
    "        days_back: Number of days of historical data to fetch\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with crypto data organized by crypto and exchange\n",
    "    \"\"\"\n",
    "    print(f\"🔄 Fetching crypto data directly from exchanges...\")\n",
    "    print(f\"🪙 Cryptocurrencies: {cryptocurrencies}\")\n",
    "    print(f\"📊 Exchanges: {exchanges}\")\n",
    "    print(f\"⏱️ Timeframe: {timeframe}\")\n",
    "    print(f\"📅 Days back: {days_back}\")\n",
    "    \n",
    "    crypto_data = {}\n",
    "    \n",
    "    # Initialize exchanges\n",
    "    exchange_instances = {}\n",
    "    for exchange_name in exchanges:\n",
    "        try:\n",
    "            if exchange_name == 'binance':\n",
    "                exchange_instances[exchange_name] = ccxt.binance({\n",
    "                    'enableRateLimit': True,\n",
    "                    'sandbox': False\n",
    "                })\n",
    "            elif exchange_name == 'okx':\n",
    "                exchange_instances[exchange_name] = ccxt.okx({\n",
    "                    'enableRateLimit': True,\n",
    "                    'sandbox': False\n",
    "                })\n",
    "            elif exchange_name == 'bybit':\n",
    "                exchange_instances[exchange_name] = ccxt.bybit({\n",
    "                    'enableRateLimit': True,\n",
    "                    'sandbox': False\n",
    "                })\n",
    "            print(f\"✅ {exchange_name.upper()} exchange initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to initialize {exchange_name}: {e}\")\n",
    "    \n",
    "    # Calculate time range\n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(days=days_back)\n",
    "    since = int(start_time.timestamp() * 1000)\n",
    "    \n",
    "    print(f\"📅 Fetching data from {start_time.date()} to {end_time.date()}\")\n",
    "    \n",
    "    # Fetch data for each cryptocurrency and exchange\n",
    "    for crypto in cryptocurrencies:\n",
    "        crypto_data[crypto] = {}\n",
    "        print(f\"\\n📈 Fetching {crypto} data...\")\n",
    "        \n",
    "        for exchange_name, exchange in exchange_instances.items():\n",
    "            print(f\"  📊 From {exchange_name.upper()}...\")\n",
    "            \n",
    "            try:\n",
    "                # Define symbol (most exchanges use this format)\n",
    "                symbol = f'{crypto}/USDT'\n",
    "                \n",
    "                # Check if symbol exists on exchange\n",
    "                markets = exchange.load_markets()\n",
    "                if symbol not in markets:\n",
    "                    print(f\"    ⚠️ {symbol} not available on {exchange_name}\")\n",
    "                    continue\n",
    "                \n",
    "                # Fetch OHLCV data in chunks\n",
    "                all_ohlcv = []\n",
    "                current_since = since\n",
    "                max_limit = 1000  # Most exchanges limit to 1000 candles per request\n",
    "                \n",
    "                while True:\n",
    "                    try:\n",
    "                        ohlcv = exchange.fetch_ohlcv(symbol, timeframe, current_since, max_limit)\n",
    "                        \n",
    "                        if not ohlcv:\n",
    "                            break\n",
    "                        \n",
    "                        all_ohlcv.extend(ohlcv)\n",
    "                        \n",
    "                        # Update timestamp for next batch\n",
    "                        current_since = ohlcv[-1][0] + 1\n",
    "                        \n",
    "                        # Progress indicator\n",
    "                        current_date = datetime.fromtimestamp(ohlcv[-1][0] / 1000)\n",
    "                        print(f\"    📊 Progress: {current_date.strftime('%Y-%m-%d')} ({len(all_ohlcv)} records)\", end='\\r')\n",
    "                        \n",
    "                        # Stop if we've reached current time\n",
    "                        if current_date >= end_time:\n",
    "                            break\n",
    "                        \n",
    "                        # Rate limiting\n",
    "                        time.sleep(exchange.rateLimit / 1000)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"    ❌ Error fetching batch: {e}\")\n",
    "                        break\n",
    "                \n",
    "                # Convert to DataFrame\n",
    "                if all_ohlcv:\n",
    "                    df = pd.DataFrame(all_ohlcv, columns=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "                    df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='ms')\n",
    "                    df.set_index('Timestamp', inplace=True)\n",
    "                    \n",
    "                    # Remove duplicates and sort\n",
    "                    df = df.drop_duplicates().sort_index()\n",
    "                    \n",
    "                    # Filter to requested date range\n",
    "                    df = df[(df.index >= start_time) & (df.index <= end_time)]\n",
    "                    \n",
    "                    # Store data\n",
    "                    crypto_data[crypto][f'{exchange_name}_spot'] = df\n",
    "                    print(f\"    ✅ {crypto} from {exchange_name}: {len(df)} records\")\n",
    "                else:\n",
    "                    print(f\"    ❌ No data retrieved for {crypto} from {exchange_name}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    ❌ Failed to fetch {crypto} from {exchange_name}: {e}\")\n",
    "    \n",
    "    return crypto_data\n",
    "\n",
    "def signed_power(x, exponent):\n",
    "    \"\"\"\n",
    "    Apply signed power: maintains sign while applying power\n",
    "    \"\"\"\n",
    "    return np.sign(x) * np.power(np.abs(x), exponent)\n",
    "\n",
    "def ts_argmax(series, window):\n",
    "    \"\"\"\n",
    "    Time-series ArgMax: returns the index of the maximum value in rolling window\n",
    "    \"\"\"\n",
    "    return series.rolling(window=window).apply(lambda x: np.argmax(x) if len(x) == window else np.nan, raw=True)\n",
    "\n",
    "def calculate_alpha1_factor(crypto_data, crypto_list=None):\n",
    "    \"\"\"\n",
    "    Calculate Alpha1 factor based on the expression:\n",
    "    (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\n",
    "    \n",
    "    Args:\n",
    "        crypto_data: Dictionary with crypto data\n",
    "        crypto_list: List of cryptos to analyze (if None, use all)\n",
    "    \n",
    "    Returns:\n",
    "        Combined DataFrame with Alpha1 factors for Alphalens analysis\n",
    "    \"\"\"\n",
    "    if crypto_list is None:\n",
    "        crypto_list = list(crypto_data.keys())\n",
    "    \n",
    "    print(f\"🧮 Calculating Alpha1 factors for: {crypto_list}\")\n",
    "    print(f\"📊 Alpha1 Expression: (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\")\n",
    "    \n",
    "    # Step 1-4: Calculate ts_argmax for all cryptos first\n",
    "    all_ts_argmax = {}\n",
    "    \n",
    "    for crypto in crypto_list:\n",
    "        if crypto not in crypto_data:\n",
    "            print(f\"❌ No data for {crypto}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"🔧 Processing {crypto} Alpha1 factor steps 1-4...\")\n",
    "        \n",
    "        # Use primary data source (prefer spot data for consistency)\n",
    "        primary_key = None\n",
    "        for key_priority in ['binance_spot', 'okx_spot', 'bybit_spot', 'binance_futures', 'okx_futures']:\n",
    "            if key_priority in crypto_data[crypto]:\n",
    "                primary_key = key_priority\n",
    "                break\n",
    "        \n",
    "        if primary_key is None:\n",
    "            print(f\"❌ No suitable data found for {crypto}\")\n",
    "            continue\n",
    "        \n",
    "        df = crypto_data[crypto][primary_key].copy()\n",
    "        print(f\"    📊 Using {primary_key} data: {len(df)} records\")\n",
    "        \n",
    "        # Calculate base components\n",
    "        close_prices = df['Close']\n",
    "        returns = close_prices.pct_change()\n",
    "        \n",
    "        print(f\"    🔢 Step 1: Calculating returns and rolling stddev...\")\n",
    "        # Calculate rolling standard deviation of returns (20 periods)\n",
    "        rolling_stddev = returns.rolling(window=20).std()\n",
    "        \n",
    "        print(f\"    🔀 Step 2: Applying conditional logic...\")\n",
    "        # Conditional: if returns < 0, use stddev(returns, 20), else use close\n",
    "        conditional_series = np.where(returns < 0, rolling_stddev, close_prices)\n",
    "        conditional_series = pd.Series(conditional_series, index=close_prices.index)\n",
    "        \n",
    "        print(f\"    ⚡ Step 3: Applying SignedPower with exponent 2...\")\n",
    "        # Apply SignedPower with exponent 2\n",
    "        signed_power_series = signed_power(conditional_series, 2.0)\n",
    "        \n",
    "        print(f\"    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\")\n",
    "        # Apply Ts_ArgMax over 5 periods\n",
    "        ts_argmax_series = ts_argmax(signed_power_series, 5)\n",
    "        \n",
    "        # Store for cross-sectional ranking\n",
    "        all_ts_argmax[crypto] = ts_argmax_series\n",
    "        print(f\"    ✅ {crypto}: {len(ts_argmax_series.dropna())} ts_argmax observations\")\n",
    "    \n",
    "    # Step 5: Cross-sectional ranking across all assets\n",
    "    print(f\"\\n📊 Step 5: Cross-sectional ranking across all assets...\")\n",
    "    if all_ts_argmax:\n",
    "        # Create DataFrame for cross-sectional ranking\n",
    "        ts_argmax_df = pd.DataFrame(all_ts_argmax)\n",
    "        ts_argmax_df = ts_argmax_df.dropna()  # Remove rows with any NaN\n",
    "        \n",
    "        print(f\"    📊 Ts_ArgMax DataFrame shape: {ts_argmax_df.shape}\")\n",
    "        print(f\"    📊 Assets: {list(ts_argmax_df.columns)}\")\n",
    "        \n",
    "        # Cross-sectional ranking: rank across assets (columns) at each date (row)\n",
    "        ranked_df = ts_argmax_df.rank(axis=1, pct=True)\n",
    "        \n",
    "        print(f\"    ✅ Cross-sectional ranking complete\")\n",
    "        \n",
    "        # Step 6: Center around 0\n",
    "        print(f\"⚖️ Step 6: Centering around 0...\")\n",
    "        alpha1_df = ranked_df - 0.5\n",
    "        \n",
    "        # Convert to multi-index format for Alphalens\n",
    "        factor_data_list = []\n",
    "        for date in alpha1_df.index:\n",
    "            for asset in alpha1_df.columns:\n",
    "                if not pd.isna(alpha1_df.loc[date, asset]):\n",
    "                    factor_data_list.append({\n",
    "                        'date': date,\n",
    "                        'asset': asset,\n",
    "                        'factor_value': alpha1_df.loc[date, asset]\n",
    "                    })\n",
    "        \n",
    "        if factor_data_list:\n",
    "            combined_factors = pd.DataFrame(factor_data_list)\n",
    "            combined_factors = combined_factors.sort_values(['date', 'asset']).reset_index(drop=True)\n",
    "            \n",
    "            print(f\"\\n✅ Alpha1 Factor calculation complete!\")\n",
    "            print(f\"📊 Total Alpha1 observations: {len(combined_factors):,}\")\n",
    "            print(f\"📈 Unique assets: {combined_factors['asset'].nunique()}\")\n",
    "            print(f\"📅 Date range: {combined_factors['date'].min()} to {combined_factors['date'].max()}\")\n",
    "            \n",
    "            return combined_factors\n",
    "        else:\n",
    "            print(\"❌ No Alpha1 factors calculated\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"❌ No ts_argmax data calculated\")\n",
    "        return None\n",
    "\n",
    "def prepare_crypto_prices_for_alphalens(crypto_data, crypto_list=None):\n",
    "    \"\"\"\n",
    "    Prepare price data for Alphalens analysis.\n",
    "    \n",
    "    Args:\n",
    "        crypto_data: Dictionary with crypto data\n",
    "        crypto_list: List of cryptos to include\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with prices (rows=dates, columns=assets)\n",
    "    \"\"\"\n",
    "    if crypto_list is None:\n",
    "        crypto_list = list(crypto_data.keys())\n",
    "    \n",
    "    print(f\"💰 Preparing price data for: {crypto_list}\")\n",
    "    \n",
    "    all_prices = {}\n",
    "    \n",
    "    for crypto in crypto_list:\n",
    "        if crypto not in crypto_data:\n",
    "            continue\n",
    "        \n",
    "        # Use primary data source (same priority as factor calculation)\n",
    "        primary_key = None\n",
    "        for key_priority in ['binance_spot', 'okx_spot', 'bybit_spot', 'binance_futures', 'okx_futures']:\n",
    "            if key_priority in crypto_data[crypto]:\n",
    "                primary_key = key_priority\n",
    "                break\n",
    "        \n",
    "        if primary_key is None:\n",
    "            continue\n",
    "        \n",
    "        df = crypto_data[crypto][primary_key]\n",
    "        all_prices[crypto] = df['Close']\n",
    "        print(f\"  📊 {crypto}: Using {primary_key} data\")\n",
    "    \n",
    "    if all_prices:\n",
    "        prices_df = pd.DataFrame(all_prices)\n",
    "        prices_df = prices_df.dropna(how='all')  # Remove rows where all assets are NaN\n",
    "        \n",
    "        print(f\"✅ Price data prepared!\")\n",
    "        print(f\"💰 Shape: {prices_df.shape}\")\n",
    "        print(f\"📅 Date range: {prices_df.index.min()} to {prices_df.index.max()}\")\n",
    "        \n",
    "        return prices_df\n",
    "    else:\n",
    "        print(\"❌ No price data prepared\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ Alpha1 factor calculation functions defined!\")\n",
    "print(\"🔧 Functions available:\")\n",
    "print(\"  - fetch_crypto_data_from_exchanges(): Fetch crypto data directly from exchanges\")\n",
    "print(\"  - calculate_alpha1_factor(): Calculate Alpha1 factor with proper cross-sectional ranking\")\n",
    "print(\"  - prepare_crypto_prices_for_alphalens(): Prepare price data\")\n",
    "print(\"  - signed_power(): Apply signed power transformation\")\n",
    "print(\"  - ts_argmax(): Time-series ArgMax calculation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08f5816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Alpha1 Factor Analysis\n",
      "============================================================\n",
      "🧮 Alpha1 Expression: (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\n",
      "============================================================\n",
      "🪙 Target cryptocurrencies - Top 10 Real Crypto (10): ['BTC', 'ETH', 'BNB', 'SOL', 'XRP', 'DOGE', 'ADA', 'AVAX', 'DOT', 'LINK']\n",
      "📊 Target exchanges: ['okx']\n",
      "\n",
      "🔄 Fetching crypto data directly from exchanges...\n",
      "🔄 Fetching crypto data directly from exchanges...\n",
      "🪙 Cryptocurrencies: ['BTC', 'ETH', 'BNB', 'SOL', 'XRP', 'DOGE', 'ADA', 'AVAX', 'DOT', 'LINK']\n",
      "📊 Exchanges: ['okx']\n",
      "⏱️ Timeframe: 1d\n",
      "📅 Days back: 365\n",
      "✅ OKX exchange initialized\n",
      "📅 Fetching data from 2024-08-01 to 2025-08-01\n",
      "\n",
      "📈 Fetching BTC data...\n",
      "  📊 From OKX...\n",
      "    ✅ BTC from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching ETH data...\n",
      "  📊 From OKX...\n",
      "    ✅ BTC from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching ETH data...\n",
      "  📊 From OKX...\n",
      "    ✅ ETH from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching BNB data...\n",
      "  📊 From OKX...\n",
      "    ✅ ETH from okx: 365 records0 records)\n",
      "\n",
      "📈 Fetching BNB data...\n",
      "  📊 From OKX...\n",
      "    ✅ BNB from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching SOL data...\n",
      "  📊 From OKX...\n",
      "    ✅ BNB from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching SOL data...\n",
      "  📊 From OKX...\n",
      "    ✅ SOL from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching XRP data...\n",
      "  📊 From OKX...\n",
      "    ✅ SOL from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching XRP data...\n",
      "  📊 From OKX...\n",
      "    ✅ XRP from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching DOGE data...\n",
      "  📊 From OKX...\n",
      "    ✅ XRP from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching DOGE data...\n",
      "  📊 From OKX...\n",
      "    ✅ DOGE from okx: 365 records records)\n",
      "\n",
      "📈 Fetching ADA data...\n",
      "  📊 From OKX...\n",
      "    ✅ DOGE from okx: 365 records records)\n",
      "\n",
      "📈 Fetching ADA data...\n",
      "  📊 From OKX...\n",
      "    ✅ ADA from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching AVAX data...\n",
      "  📊 From OKX...\n",
      "    ✅ ADA from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching AVAX data...\n",
      "  📊 From OKX...\n",
      "    ✅ AVAX from okx: 365 records records)\n",
      "\n",
      "📈 Fetching DOT data...\n",
      "  📊 From OKX...\n",
      "    ✅ AVAX from okx: 365 records records)\n",
      "\n",
      "📈 Fetching DOT data...\n",
      "  📊 From OKX...\n",
      "    ✅ DOT from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching LINK data...\n",
      "  📊 From OKX...\n",
      "    ✅ DOT from okx: 365 records5 records)\n",
      "\n",
      "📈 Fetching LINK data...\n",
      "  📊 From OKX...\n",
      "    ✅ LINK from okx: 365 records records)\n",
      "\n",
      "📊 CRYPTO DATA SUMMARY:\n",
      "==================================================\n",
      "🪙 Total cryptocurrencies requested: 10\n",
      "🪙 Successfully fetched: 10\n",
      "📈 Available cryptos: ['BTC', 'ETH', 'BNB', 'SOL', 'XRP', 'DOGE', 'ADA', 'AVAX', 'DOT', 'LINK']\n",
      "\n",
      "💰 PREPARING PRICE DATA (rows=dates, columns=assets):\n",
      "============================================================\n",
      "📊 BTC: 365 price records from okx_spot\n",
      "📊 ETH: 365 price records from okx_spot\n",
      "📊 BNB: 365 price records from okx_spot\n",
      "📊 SOL: 365 price records from okx_spot\n",
      "📊 XRP: 365 price records from okx_spot\n",
      "📊 DOGE: 365 price records from okx_spot\n",
      "📊 ADA: 365 price records from okx_spot\n",
      "📊 AVAX: 365 price records from okx_spot\n",
      "📊 DOT: 365 price records from okx_spot\n",
      "📊 LINK: 365 price records from okx_spot\n",
      "\n",
      "✅ PRICE DATA PREPARED!\n",
      "📊 Shape: (365, 10) (rows=dates, columns=assets)\n",
      "📅 Date range: 2024-08-02 00:00:00 to 2025-08-01 00:00:00\n",
      "\n",
      "📈 FIRST 5 ROWS OF PRICE DATA:\n",
      "--------------------------------------------------\n",
      "    ✅ LINK from okx: 365 records records)\n",
      "\n",
      "📊 CRYPTO DATA SUMMARY:\n",
      "==================================================\n",
      "🪙 Total cryptocurrencies requested: 10\n",
      "🪙 Successfully fetched: 10\n",
      "📈 Available cryptos: ['BTC', 'ETH', 'BNB', 'SOL', 'XRP', 'DOGE', 'ADA', 'AVAX', 'DOT', 'LINK']\n",
      "\n",
      "💰 PREPARING PRICE DATA (rows=dates, columns=assets):\n",
      "============================================================\n",
      "📊 BTC: 365 price records from okx_spot\n",
      "📊 ETH: 365 price records from okx_spot\n",
      "📊 BNB: 365 price records from okx_spot\n",
      "📊 SOL: 365 price records from okx_spot\n",
      "📊 XRP: 365 price records from okx_spot\n",
      "📊 DOGE: 365 price records from okx_spot\n",
      "📊 ADA: 365 price records from okx_spot\n",
      "📊 AVAX: 365 price records from okx_spot\n",
      "📊 DOT: 365 price records from okx_spot\n",
      "📊 LINK: 365 price records from okx_spot\n",
      "\n",
      "✅ PRICE DATA PREPARED!\n",
      "📊 Shape: (365, 10) (rows=dates, columns=assets)\n",
      "📅 Date range: 2024-08-02 00:00:00 to 2025-08-01 00:00:00\n",
      "\n",
      "📈 FIRST 5 ROWS OF PRICE DATA:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC</th>\n",
       "      <th>ETH</th>\n",
       "      <th>BNB</th>\n",
       "      <th>SOL</th>\n",
       "      <th>XRP</th>\n",
       "      <th>DOGE</th>\n",
       "      <th>ADA</th>\n",
       "      <th>AVAX</th>\n",
       "      <th>DOT</th>\n",
       "      <th>LINK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-02</th>\n",
       "      <td>61489.9</td>\n",
       "      <td>2989.61</td>\n",
       "      <td>543.1</td>\n",
       "      <td>152.74</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>0.11155</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>23.607</td>\n",
       "      <td>5.126</td>\n",
       "      <td>11.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-03</th>\n",
       "      <td>60710.0</td>\n",
       "      <td>2903.79</td>\n",
       "      <td>529.5</td>\n",
       "      <td>142.52</td>\n",
       "      <td>0.5559</td>\n",
       "      <td>0.10813</td>\n",
       "      <td>0.3647</td>\n",
       "      <td>22.670</td>\n",
       "      <td>5.043</td>\n",
       "      <td>11.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-04</th>\n",
       "      <td>58160.1</td>\n",
       "      <td>2689.15</td>\n",
       "      <td>496.9</td>\n",
       "      <td>138.32</td>\n",
       "      <td>0.5229</td>\n",
       "      <td>0.10375</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>21.250</td>\n",
       "      <td>4.687</td>\n",
       "      <td>10.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-05</th>\n",
       "      <td>54018.0</td>\n",
       "      <td>2419.73</td>\n",
       "      <td>464.3</td>\n",
       "      <td>129.78</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>19.539</td>\n",
       "      <td>4.197</td>\n",
       "      <td>9.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-06</th>\n",
       "      <td>56022.0</td>\n",
       "      <td>2461.21</td>\n",
       "      <td>484.9</td>\n",
       "      <td>144.45</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>0.09643</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>20.898</td>\n",
       "      <td>4.510</td>\n",
       "      <td>10.066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                BTC      ETH    BNB     SOL     XRP     DOGE     ADA    AVAX  \\\n",
       "Timestamp                                                                      \n",
       "2024-08-02  61489.9  2989.61  543.1  152.74  0.5606  0.11155  0.3636  23.607   \n",
       "2024-08-03  60710.0  2903.79  529.5  142.52  0.5559  0.10813  0.3647  22.670   \n",
       "2024-08-04  58160.1  2689.15  496.9  138.32  0.5229  0.10375  0.3440  21.250   \n",
       "2024-08-05  54018.0  2419.73  464.3  129.78  0.4889  0.09434  0.3118  19.539   \n",
       "2024-08-06  56022.0  2461.21  484.9  144.45  0.5060  0.09643  0.3310  20.898   \n",
       "\n",
       "              DOT    LINK  \n",
       "Timestamp                  \n",
       "2024-08-02  5.126  11.920  \n",
       "2024-08-03  5.043  11.683  \n",
       "2024-08-04  4.687  10.887  \n",
       "2024-08-05  4.197   9.486  \n",
       "2024-08-06  4.510  10.066  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧮 CALCULATING ALPHA1 FACTORS (Cross-Sectional Ranking):\n",
      "============================================================\n",
      "📊 Alpha1 Formula: (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\n",
      "🎯 Using TRUE cross-sectional ranking: assets ranked against each other at each date\n",
      "🧮 Calculating Alpha1 factors for: ['BTC', 'ETH', 'BNB', 'SOL', 'XRP', 'DOGE', 'ADA', 'AVAX', 'DOT', 'LINK']\n",
      "📊 Alpha1 Expression: (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\n",
      "🔧 Processing BTC Alpha1 factor steps 1-4...\n",
      "    📊 Using okx_spot data: 365 records\n",
      "    🔢 Step 1: Calculating returns and rolling stddev...\n",
      "    🔀 Step 2: Applying conditional logic...\n",
      "    ⚡ Step 3: Applying SignedPower with exponent 2...\n",
      "    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\n",
      "    ✅ BTC: 342 ts_argmax observations\n",
      "🔧 Processing ETH Alpha1 factor steps 1-4...\n",
      "    📊 Using okx_spot data: 365 records\n",
      "    🔢 Step 1: Calculating returns and rolling stddev...\n",
      "    🔀 Step 2: Applying conditional logic...\n",
      "    ⚡ Step 3: Applying SignedPower with exponent 2...\n",
      "    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\n",
      "    ✅ ETH: 342 ts_argmax observations\n",
      "🔧 Processing BNB Alpha1 factor steps 1-4...\n",
      "    📊 Using okx_spot data: 365 records\n",
      "    🔢 Step 1: Calculating returns and rolling stddev...\n",
      "    🔀 Step 2: Applying conditional logic...\n",
      "    ⚡ Step 3: Applying SignedPower with exponent 2...\n",
      "    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\n",
      "    ✅ BNB: 344 ts_argmax observations\n",
      "🔧 Processing SOL Alpha1 factor steps 1-4...\n",
      "    📊 Using okx_spot data: 365 records\n",
      "    🔢 Step 1: Calculating returns and rolling stddev...\n",
      "    🔀 Step 2: Applying conditional logic...\n",
      "    ⚡ Step 3: Applying SignedPower with exponent 2...\n",
      "    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\n",
      "    ✅ SOL: 342 ts_argmax observations\n",
      "🔧 Processing XRP Alpha1 factor steps 1-4...\n",
      "    📊 Using okx_spot data: 365 records\n",
      "    🔢 Step 1: Calculating returns and rolling stddev...\n",
      "    🔀 Step 2: Applying conditional logic...\n",
      "    ⚡ Step 3: Applying SignedPower with exponent 2...\n",
      "    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\n",
      "    ✅ XRP: 342 ts_argmax observations\n",
      "🔧 Processing DOGE Alpha1 factor steps 1-4...\n",
      "    📊 Using okx_spot data: 365 records\n",
      "    🔢 Step 1: Calculating returns and rolling stddev...\n",
      "    🔀 Step 2: Applying conditional logic...\n",
      "    ⚡ Step 3: Applying SignedPower with exponent 2...\n",
      "    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\n",
      "    ✅ DOGE: 344 ts_argmax observations\n",
      "🔧 Processing ADA Alpha1 factor steps 1-4...\n",
      "    📊 Using okx_spot data: 365 records\n",
      "    🔢 Step 1: Calculating returns and rolling stddev...\n",
      "    🔀 Step 2: Applying conditional logic...\n",
      "    ⚡ Step 3: Applying SignedPower with exponent 2...\n",
      "    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\n",
      "    ✅ ADA: 344 ts_argmax observations\n",
      "🔧 Processing AVAX Alpha1 factor steps 1-4...\n",
      "    📊 Using okx_spot data: 365 records\n",
      "    🔢 Step 1: Calculating returns and rolling stddev...\n",
      "    🔀 Step 2: Applying conditional logic...\n",
      "    ⚡ Step 3: Applying SignedPower with exponent 2...\n",
      "    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\n",
      "    ✅ AVAX: 347 ts_argmax observations\n",
      "🔧 Processing DOT Alpha1 factor steps 1-4...\n",
      "    📊 Using okx_spot data: 365 records\n",
      "    🔢 Step 1: Calculating returns and rolling stddev...\n",
      "    🔀 Step 2: Applying conditional logic...\n",
      "    ⚡ Step 3: Applying SignedPower with exponent 2...\n",
      "    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\n",
      "    ✅ DOT: 347 ts_argmax observations\n",
      "🔧 Processing LINK Alpha1 factor steps 1-4...\n",
      "    📊 Using okx_spot data: 365 records\n",
      "    🔢 Step 1: Calculating returns and rolling stddev...\n",
      "    🔀 Step 2: Applying conditional logic...\n",
      "    ⚡ Step 3: Applying SignedPower with exponent 2...\n",
      "    🎯 Step 4: Calculating Ts_ArgMax over 5 periods...\n",
      "    ✅ LINK: 344 ts_argmax observations\n",
      "\n",
      "📊 Step 5: Cross-sectional ranking across all assets...\n",
      "    📊 Ts_ArgMax DataFrame shape: (342, 10)\n",
      "    📊 Assets: ['BTC', 'ETH', 'BNB', 'SOL', 'XRP', 'DOGE', 'ADA', 'AVAX', 'DOT', 'LINK']\n",
      "    ✅ Cross-sectional ranking complete\n",
      "⚖️ Step 6: Centering around 0...\n",
      "\n",
      "✅ Alpha1 Factor calculation complete!\n",
      "📊 Total Alpha1 observations: 3,420\n",
      "📈 Unique assets: 10\n",
      "📅 Date range: 2024-08-25 00:00:00 to 2025-08-01 00:00:00\n",
      "\n",
      "✅ ALPHA1 FACTOR DATA PREPARED!\n",
      "📊 Total Alpha1 observations: 3,420\n",
      "📈 Factor structure: Multi-Index Series (date, asset)\n",
      "🎯 Unique assets: 10\n",
      "🎯 Unique dates: 342\n",
      "🧮 Factor range: [-0.4000, 0.5000]\n",
      "📊 Factor mean: 0.0500, std: 0.2125\n",
      "\n",
      "📊 FIRST 10 OBSERVATIONS OF ALPHA1 FACTOR DATA:\n",
      "--------------------------------------------------\n",
      "\n",
      "✅ Alpha1 Factor calculation complete!\n",
      "📊 Total Alpha1 observations: 3,420\n",
      "📈 Unique assets: 10\n",
      "📅 Date range: 2024-08-25 00:00:00 to 2025-08-01 00:00:00\n",
      "\n",
      "✅ ALPHA1 FACTOR DATA PREPARED!\n",
      "📊 Total Alpha1 observations: 3,420\n",
      "📈 Factor structure: Multi-Index Series (date, asset)\n",
      "🎯 Unique assets: 10\n",
      "🎯 Unique dates: 342\n",
      "🧮 Factor range: [-0.4000, 0.5000]\n",
      "📊 Factor mean: 0.0500, std: 0.2125\n",
      "\n",
      "📊 FIRST 10 OBSERVATIONS OF ALPHA1 FACTOR DATA:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date        asset\n",
       "2024-08-25  ADA      0.10\n",
       "            AVAX     0.10\n",
       "            BNB     -0.35\n",
       "            BTC      0.50\n",
       "            DOGE    -0.35\n",
       "            DOT      0.10\n",
       "            ETH      0.10\n",
       "            LINK     0.10\n",
       "            SOL      0.10\n",
       "            XRP      0.10\n",
       "Name: alpha1_factor, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 ALPHA1 FACTOR DATA STRUCTURE INFO:\n",
      "----------------------------------------\n",
      "Index levels: ['date', 'asset']\n",
      "Data type: <class 'pandas.core.series.Series'>\n",
      "Value type: float64\n",
      "\n",
      "🔍 CROSS-SECTIONAL RANKING VALIDATION:\n",
      "----------------------------------------\n",
      "📅 Sample date: 2024-08-30 00:00:00\n",
      "📊 Factor values (sorted):\n",
      "   SOL: -0.4000\n",
      "   BNB: -0.1500\n",
      "   ETH: -0.1500\n",
      "   LINK: -0.1500\n",
      "   XRP: -0.1500\n",
      "   ADA: 0.1500\n",
      "   BTC: 0.1500\n",
      "   AVAX: 0.4000\n",
      "   DOGE: 0.4000\n",
      "   DOT: 0.4000\n",
      "🎯 Range: [-0.4000, 0.4000] ✓ Centered around 0\n",
      "\n",
      "🔍 ALPHA1 DATA VALIDATION SUMMARY:\n",
      "==================================================\n",
      "📅 Price data dates: 365\n",
      "📅 Alpha1 factor dates: 342\n",
      "📅 Common dates: 342\n",
      "📊 Date overlap: 93.7%\n",
      "🪙 Price data assets: ['ADA', 'AVAX', 'BNB', 'BTC', 'DOGE', 'DOT', 'ETH', 'LINK', 'SOL', 'XRP']\n",
      "🪙 Alpha1 factor assets: ['ADA', 'AVAX', 'BNB', 'BTC', 'DOGE', 'DOT', 'ETH', 'LINK', 'SOL', 'XRP']\n",
      "🪙 Common assets: ['ADA', 'AVAX', 'BNB', 'BTC', 'DOGE', 'DOT', 'ETH', 'LINK', 'SOL', 'XRP']\n",
      "\n",
      "✅ ALPHA1 DATASETS READY FOR ALPHALENS ANALYSIS!\n",
      "💰 Price DataFrame: (365, 10)\n",
      "🧮 Alpha1 Factor Series: 3,420 observations\n",
      "🎯 Cross-sectional ranking: Assets compared to each other at each date ✓\n",
      "\n",
      "🎯 Next steps: Use Alpha1 factor for Alphalens analysis\n",
      "🧮 Alpha1 measures complex momentum/volatility interaction with proper cross-sectional ranking\n"
     ]
    }
   ],
   "source": [
    "# Fetch Crypto Data and Prepare Alpha1 Factor & Price Datasets\n",
    "print(\"🚀 Starting Alpha1 Factor Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(\"🧮 Alpha1 Expression: (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define cryptocurrencies to analyze - Top 10 \"Real\" Crypto (No Stablecoins)\n",
    "target_cryptos = ['BTC', 'ETH', 'BNB', 'SOL', 'XRP', 'DOGE', 'ADA', 'AVAX', 'DOT', 'LINK']  # Top 10 real cryptocurrencies\n",
    "target_exchanges = ['okx']  # Using only OKX for cleaner factor analysis\n",
    "\n",
    "print(f\"🪙 Target cryptocurrencies - Top 10 Real Crypto ({len(target_cryptos)}): {target_cryptos}\")\n",
    "print(f\"📊 Target exchanges: {target_exchanges}\")\n",
    "\n",
    "# Fetch crypto data directly from exchanges\n",
    "print(f\"\\n🔄 Fetching crypto data directly from exchanges...\")\n",
    "\n",
    "crypto_data = fetch_crypto_data_from_exchanges(\n",
    "    cryptocurrencies=target_cryptos,\n",
    "    exchanges=target_exchanges,\n",
    "    timeframe='1d',  # Daily data for cleaner analysis\n",
    "    days_back=365    # Full 1 year of daily data (365 data points)\n",
    ")\n",
    "\n",
    "# Display summary of fetched data\n",
    "print(f\"\\n📊 CRYPTO DATA SUMMARY:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "successful_cryptos = [crypto for crypto in crypto_data.keys() if crypto_data[crypto]]\n",
    "\n",
    "print(f\"🪙 Total cryptocurrencies requested: {len(target_cryptos)}\")\n",
    "print(f\"🪙 Successfully fetched: {len(successful_cryptos)}\")\n",
    "print(f\"📈 Available cryptos: {successful_cryptos}\")\n",
    "\n",
    "if len(successful_cryptos) < len(target_cryptos):\n",
    "    failed_cryptos = set(target_cryptos) - set(successful_cryptos)\n",
    "    print(f\"❌ Failed to fetch: {list(failed_cryptos)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. PREPARE PRICE DATA: DataFrame with rows=dates, columns=assets\n",
    "# =============================================================================\n",
    "print(f\"\\n💰 PREPARING PRICE DATA (rows=dates, columns=assets):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "price_data = {}\n",
    "\n",
    "for crypto in successful_cryptos:\n",
    "    if crypto_data[crypto]:\n",
    "        # Use first available exchange data\n",
    "        exchange_key = list(crypto_data[crypto].keys())[0]\n",
    "        df = crypto_data[crypto][exchange_key]\n",
    "        price_data[crypto] = df['Close']\n",
    "        print(f\"📊 {crypto}: {len(df)} price records from {exchange_key}\")\n",
    "\n",
    "# Create price DataFrame: rows=dates, columns=assets\n",
    "if price_data:\n",
    "    prices_df = pd.DataFrame(price_data)\n",
    "    prices_df = prices_df.dropna()  # Remove rows with any NaN values\n",
    "    \n",
    "    print(f\"\\n✅ PRICE DATA PREPARED!\")\n",
    "    print(f\"📊 Shape: {prices_df.shape} (rows=dates, columns=assets)\")\n",
    "    print(f\"📅 Date range: {prices_df.index.min()} to {prices_df.index.max()}\")\n",
    "    \n",
    "    print(f\"\\n📈 FIRST 5 ROWS OF PRICE DATA:\")\n",
    "    print(\"-\" * 50)\n",
    "    display(prices_df.head())\n",
    "else:\n",
    "    print(\"❌ No price data prepared\")\n",
    "    prices_df = None\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CALCULATE ALPHA1 FACTORS: Multi-Index Pandas Series (Cross-Sectional Ranking)\n",
    "# =============================================================================\n",
    "print(f\"\\n🧮 CALCULATING ALPHA1 FACTORS (Cross-Sectional Ranking):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"📊 Alpha1 Formula: (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\")\n",
    "print(f\"🎯 Using TRUE cross-sectional ranking: assets ranked against each other at each date\")\n",
    "\n",
    "# Use the corrected Alpha1 factor calculation function\n",
    "alpha1_factor_data = calculate_alpha1_factor(crypto_data, successful_cryptos)\n",
    "\n",
    "# Create Multi-Index Series for Alpha1 factors\n",
    "if alpha1_factor_data is not None:\n",
    "    # Create multi-index: (date, asset) - only 2 levels\n",
    "    factor_series = alpha1_factor_data.set_index(['date', 'asset'])['factor_value']\n",
    "    factor_series.name = 'alpha1_factor'\n",
    "    \n",
    "    print(f\"\\n✅ ALPHA1 FACTOR DATA PREPARED!\")\n",
    "    print(f\"📊 Total Alpha1 observations: {len(factor_series):,}\")\n",
    "    print(f\"📈 Factor structure: Multi-Index Series (date, asset)\")\n",
    "    print(f\"🎯 Unique assets: {factor_series.index.get_level_values('asset').nunique()}\")\n",
    "    print(f\"🎯 Unique dates: {factor_series.index.get_level_values('date').nunique()}\")\n",
    "    print(f\"🧮 Factor range: [{factor_series.min():.4f}, {factor_series.max():.4f}]\")\n",
    "    print(f\"📊 Factor mean: {factor_series.mean():.4f}, std: {factor_series.std():.4f}\")\n",
    "    \n",
    "    print(f\"\\n📊 FIRST 10 OBSERVATIONS OF ALPHA1 FACTOR DATA:\")\n",
    "    print(\"-\" * 50)\n",
    "    display(factor_series.head(10))\n",
    "    \n",
    "    print(f\"\\n📊 ALPHA1 FACTOR DATA STRUCTURE INFO:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Index levels: {factor_series.index.names}\")\n",
    "    print(f\"Data type: {type(factor_series)}\")\n",
    "    print(f\"Value type: {factor_series.dtype}\")\n",
    "    \n",
    "    # Show cross-sectional ranking validation\n",
    "    print(f\"\\n🔍 CROSS-SECTIONAL RANKING VALIDATION:\")\n",
    "    print(\"-\" * 40)\n",
    "    sample_date = factor_series.index.get_level_values('date')[50]  # Pick a sample date\n",
    "    sample_factors = factor_series.xs(sample_date, level='date').sort_values()\n",
    "    print(f\"📅 Sample date: {sample_date}\")\n",
    "    print(f\"📊 Factor values (sorted):\")\n",
    "    for asset, value in sample_factors.items():\n",
    "        print(f\"   {asset}: {value:.4f}\")\n",
    "    print(f\"🎯 Range: [{sample_factors.min():.4f}, {sample_factors.max():.4f}] ✓ Centered around 0\")\n",
    "else:\n",
    "    print(\"❌ No Alpha1 factor data calculated\")\n",
    "    factor_series = None\n",
    "\n",
    "# =============================================================================\n",
    "# 3. DATA VALIDATION & SUMMARY\n",
    "# =============================================================================\n",
    "print(f\"\\n🔍 ALPHA1 DATA VALIDATION SUMMARY:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if prices_df is not None and factor_series is not None:\n",
    "    # Check date alignment\n",
    "    price_dates = set(prices_df.index)\n",
    "    factor_dates = set(factor_series.index.get_level_values('date'))\n",
    "    common_dates = price_dates & factor_dates\n",
    "    \n",
    "    print(f\"📅 Price data dates: {len(price_dates):,}\")\n",
    "    print(f\"📅 Alpha1 factor dates: {len(factor_dates):,}\")\n",
    "    print(f\"📅 Common dates: {len(common_dates):,}\")\n",
    "    print(f\"📊 Date overlap: {len(common_dates)/max(len(price_dates), len(factor_dates))*100:.1f}%\")\n",
    "    \n",
    "    # Check asset alignment\n",
    "    price_assets = set(prices_df.columns)\n",
    "    factor_assets = set(factor_series.index.get_level_values('asset'))\n",
    "    common_assets = price_assets & factor_assets\n",
    "    \n",
    "    print(f\"🪙 Price data assets: {sorted(price_assets)}\")\n",
    "    print(f\"🪙 Alpha1 factor assets: {sorted(factor_assets)}\")\n",
    "    print(f\"🪙 Common assets: {sorted(common_assets)}\")\n",
    "    \n",
    "    print(f\"\\n✅ ALPHA1 DATASETS READY FOR ALPHALENS ANALYSIS!\")\n",
    "    print(f\"💰 Price DataFrame: {prices_df.shape}\")\n",
    "    print(f\"🧮 Alpha1 Factor Series: {len(factor_series):,} observations\")\n",
    "    print(f\"🎯 Cross-sectional ranking: Assets compared to each other at each date ✓\")\n",
    "else:\n",
    "    print(\"❌ Alpha1 data preparation failed\")\n",
    "\n",
    "print(f\"\\n🎯 Next steps: Use Alpha1 factor for Alphalens analysis\")\n",
    "print(f\"🧮 Alpha1 measures complex momentum/volatility interaction with proper cross-sectional ranking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21514de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Running Alphalens analysis for Alpha1 factor...\n",
      "🧮 Alpha1 Expression: (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\n",
      "📊 Forward return periods: (1, 5, 10, 20) days\n",
      "📊 Quantiles: 5 (for factor ranking)\n",
      "Dropped 99.7% entries from factor data: 5.8% in forward returns computation and 93.9% in binning phase (set max_loss=0 to see potentially suppressed Exceptions).\n"
     ]
    },
    {
     "ename": "MaxLossExceededError",
     "evalue": "max_loss (35.0%) exceeded 99.7%, consider increasing it.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMaxLossExceededError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m📊 Quantiles: 5 (for factor ranking)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Prepare factor and forward returns data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m ret = \u001b[43mget_clean_factor_and_forward_returns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfactor_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprices_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mperiods\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 1D, 5D, 10D, 20D forward returns\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Divide into quintiles\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# No grouping\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Alpha1 factor and forward returns data prepared!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m📊 Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adrianlam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\alphalens\\utils.py:850\u001b[39m, in \u001b[36mget_clean_factor_and_forward_returns\u001b[39m\u001b[34m(factor, prices, groupby, binning_by_group, quantiles, bins, periods, filter_zscore, groupby_labels, max_loss, zero_aware, cumulative_returns)\u001b[39m\n\u001b[32m    696\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    697\u001b[39m \u001b[33;03mFormats the factor data, pricing data, and group mappings into a DataFrame\u001b[39;00m\n\u001b[32m    698\u001b[39m \u001b[33;03mthat contains aligned MultiIndex indices of timestamp and asset. The\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    843\u001b[39m \u001b[33;03m    For use when forward returns are already available.\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    846\u001b[39m forward_returns = compute_forward_returns(\n\u001b[32m    847\u001b[39m     factor, prices, periods, filter_zscore, cumulative_returns\n\u001b[32m    848\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m factor_data = \u001b[43mget_clean_factor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforward_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroupby_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroupby_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquantiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbinning_by_group\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbinning_by_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43mzero_aware\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_aware\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m factor_data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adrianlam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\alphalens\\utils.py:676\u001b[39m, in \u001b[36mget_clean_factor\u001b[39m\u001b[34m(factor, forward_returns, groupby, binning_by_group, quantiles, bins, groupby_labels, max_loss, zero_aware)\u001b[39m\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tot_loss > max_loss:\n\u001b[32m    672\u001b[39m     message = \u001b[33m\"\u001b[39m\u001b[33mmax_loss (\u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[33m) exceeded \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[33m, consider increasing it.\u001b[39m\u001b[33m\"\u001b[39m % (\n\u001b[32m    673\u001b[39m         max_loss * \u001b[32m100\u001b[39m,\n\u001b[32m    674\u001b[39m         tot_loss * \u001b[32m100\u001b[39m,\n\u001b[32m    675\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m676\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxLossExceededError(message)\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mmax_loss is \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[33m, not exceeded: OK!\u001b[39m\u001b[33m\"\u001b[39m % (max_loss * \u001b[32m100\u001b[39m))\n",
      "\u001b[31mMaxLossExceededError\u001b[39m: max_loss (35.0%) exceeded 99.7%, consider increasing it."
     ]
    }
   ],
   "source": [
    "# Alphalens Analysis for Alpha1 Factor\n",
    "from alphalens.utils import get_clean_factor_and_forward_returns\n",
    "\n",
    "print(f\"🔬 Running Alphalens analysis for Alpha1 factor...\")\n",
    "print(f\"🧮 Alpha1 Expression: (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)\")\n",
    "print(f\"📊 Forward return periods: (1, 5, 10, 20) days\")\n",
    "print(f\"📊 Quantiles: 5 (for factor ranking)\")\n",
    "\n",
    "# Prepare factor and forward returns data\n",
    "ret = get_clean_factor_and_forward_returns(\n",
    "    factor_series, \n",
    "    prices_df, \n",
    "    periods=(1, 5, 10, 20),  # 1D, 5D, 10D, 20D forward returns\n",
    "    quantiles=5,             # Divide into quintiles\n",
    "    groupby=None             # No grouping\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Alpha1 factor and forward returns data prepared!\")\n",
    "print(f\"📊 Shape: {ret.shape}\")\n",
    "print(f\"📈 Columns: {list(ret.columns)}\")\n",
    "print(f\"🧮 Alpha1 Factor Summary:\")\n",
    "print(f\"   - Range: [{ret['factor'].min():.4f}, {ret['factor'].max():.4f}]\")\n",
    "print(f\"   - Mean: {ret['factor'].mean():.4f}\")\n",
    "print(f\"   - Std: {ret['factor'].std():.4f}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\n📊 FIRST 10 ROWS OF PREPARED DATA:\")\n",
    "display(ret.head(10))\n",
    "\n",
    "# Create comprehensive tear sheet for Alpha1 analysis\n",
    "print(f\"\\n📈 Generating comprehensive Alpha1 factor analysis...\")\n",
    "alphalens.tears.create_full_tear_sheet(ret)\n",
    "\n",
    "print(f\"\\n🎯 Alpha1 Factor Analysis Complete!\")\n",
    "print(f\"🧮 This factor combines:\")\n",
    "print(f\"   - Conditional volatility vs price logic\")\n",
    "print(f\"   - Signed power transformation\")\n",
    "print(f\"   - Time-series momentum patterns\")\n",
    "print(f\"   - Cross-sectional ranking\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
